\documentclass{llncs}
\usepackage{epsfig}
% \usepackage{color}
\usepackage{alltt}
\usepackage{ulem}
\normalem

\begin{document}

\newcommand{\name}[1]{{\sf\textsl{#1}}}        % objects/processes
\newcommand{\vat}[1]{{\sf Vat{#1}}}            % vats
\newcommand{\pr}[1]{{#1}}                      % principals
\newcommand{\code}[1]{{\tt {#1}}}              % code
\newcommand{\var}[1]{{\tt {#1}}}               % variables
\newcommand{\dvar}[1]{{\textsl{#1}}}           % declarations of variables
\newcommand{\dobj}[1]{{\textsl{#1}}}           % declarations of objects
\newcommand{\meth}[1]{{\tt {#1}}}              % methods
\newcommand{\dmeth}[1]{{\tt {#1}}}             % declarations of methods
\newcommand{\cls}[1]{{\tt {#1}}}               % classes
\newcommand{\ex}[1]{{\tt {#1}}}                % exceptions
\newcommand{\abst}[1]{{#1}}                    % design abstractions
% \newcommand{\sys}[1]{{sc {#1}}}              % systems and languages
\newcommand{\sys}[1]{{#1}}                     % systems and languages

\newcommand{\oops}[1]{{\it (**{#1}**)}}        % Notes to ourselves, on
% \newcommand{\oops}[1]{}                        % Notes to ourselves, off

\newcommand{\related}[1]{\subsubsection{{#1}}}
% \newcommand{\related}[1]{\textbf{{#1}}}

\def\twiddle{\raisebox{0.3ex}{\mbox{\tiny $\sim$}}}



\title{Concurrency Among Strangers}
\subtitle{Programming in E as Plan Coordination}

\author{Mark S. Miller\inst{1,2} \and 
  E. Dean Tribble \and
  Jonathan Shapiro\inst{2}}

\institute{Johns Hopkins University
\and Hewlett Packard Laboratories}

\maketitle

\sloppypar

\begin{abstract}
Programmers write programs, expressing plans for machines to
execute. When we compose programs, so they may cooperate, they may
instead interfere with each other in unanticipated ways. \emph{Plan
coordination} is the art of simultaneously enabling plans to
cooperate, while avoiding hazards of destructive plan
interference. For sequential computation within a single machine,
object programming has provided impressive successes at plan
coordination.\\

In Internet-scale computing, machines proceed concurrently, interact
across barriers of large latencies and partial failure, and encounter
each other's misbehavior. Each dimension presents new plan
coordination challenges. As an example, we show how hard it is to use
locking to prevent concurrent plans from interfering without
destroying their ability to cooperate.\\

This paper explains how, by changing only a few concepts of
conventional sequential object programming, the E language addresses
these joint challenges. Several projects are adapting these insights
to existing platforms.
\end{abstract}

\section{Introduction}

The fundamental constraint we face as programmers is complexity. It
might seem that we could successfully formulate plans only for systems
we can understand. Instead, every day, massive numbers of programmers
successfully contribute code towards working systems too complex for
anyone to understand \emph{as a whole}. We make use of modularity and
abstraction mechanisms to construct systems whose component plans we
can understand piecemeal, and whose compositions we can understand
without fully understanding each plan being composed.
%
\begin{quote}
Programmers are not to be measured by their ingenuity and their logic
but by the completeness of their case analysis.
\begin{flushright}
---Alan Perlis
\end{flushright}
\end{quote}
%
In the human world, when you plan for yourself, you make assumptions
about future situations in which your plan will unfold. Occasionally,
someone else's plan may interfere with yours, invalidating the
assumptions on which your plan is based. To plan successfully, you
need some sense of which assumptions are usually safe from such
disruption. But you don't need to anticipate every possible
contingency. If someone does something you didn't expect, you'll
probably be better able to figure out how to cope at that time anyway.

To formulate plans for machines to execute, programmers must also make
assumptions. When separately formulated plans are composed,
conflicting assumptions can cause the run-time situation to become
\emph{inconsistent} with a given plan's assumptions, leading it
awry. By dividing the state of a computational system into separately
encapsulated objects, and by giving objects limited access to each
other, we limit outside interference, extending the range of
assumptions our programs may safely rely upon.\footnote{
%
This view of encapsulation and composition parallels Hayek's
explanation of how property rights protects humans plans from
interference, and how trade brings about their cooperative alignment
\cite{Hayek:1945:UKS}. See \cite{miller:agoric,tulloh:abstraction} for
more.}
%
Beyond these assumptions, correct programs must handle all relevant
contingencies. By abstraction, we limit one object's need for
knowledge of others, reducing the number of cases which are
relevant. Even under sequential and benign conditions, the remaining
case analysis can still be quite painful.

Under concurrency, an object's own plans may destructively interfere
with itself. In distributed programming, asynchrony and partial
failure limit an object's local knowledge of relevant facts,
increasing the number of relevant cases it must consider. In secure
programming, we carefully distinguish those objects whose good
behavior we rely on from those we don't, but we seek to cooperate with
both. Confidentiality further constrains local knowledge; deceit and
malice are further sources of possible plan interference. Each of
these dimensions threatens an explosion of new cases we must
consider. To succeed, we must find ways of reducing the size of the
resulting case analysis.

Previous papers have focused on E's support for limited trust within
the constraints of distributed systems
\cite{miller:ode,miller:myths,miller:paradigm,miller:struct-auth}. This
paper focuses on E's support for concurrent and distributed
programming within the constraints of limited trust.

\section{Overview}

Throughout this paper, we do not seek ``solutions'' to coordination
problems, but rather, abstraction mechanisms adequate to craft diverse
solutions adapted to the needs of many applications. We illustrate
many of our points with a simple example, a ``\abst{statusHolder}''
object implementing the listener pattern.
%
\begin{description}
\item[The Sequential StatusHolder] introduces the \abst{statusHolder}
and examines its hazards in a sequential environment.

\item[Why Not Shared-state Concurrency.] This section shows several
attempts at a conventionally thread-safe \abst{statusHolder} in
\sys{Java}, and the ways each suffers from plan interference by
interleaving.

\item[A Taste of E] shows a \abst{statusHolder} written in E and explains
E's eventual-send operator in the context of a single thread of
control.

\item[Communicating Event Loops] explains how our \abst{statusHolder}
handles concurrency and distribution under benign conditions.

\item[Mutual Suspicion] examines how the plans coordinated by our
\abst{statusHolder} are and are not vulnerable to each other.

\item[Promise Pipelining] introduces promises for the results of
eventually-sent messages, shows how the resulting pipelining helps us
tolerate latency, and how broken promise contagion lets us handle
eventually-thrown exceptions.

\item[Partial Failure] shows how \abst{statusHolder}'s clients can
regain access following a partition or crash, and explains the issues
involved in regaining distributed consistency.

\item[The When-Catch Expression] explains how to turn data-flow back
into control-flow.

\item[From Objects to Actors and Back Again.] This section presents a
brief history of E's concurrency control.

\item[Related Work] discusses other systems with similar goals, as
well as current projects adapting these insights to existing
platforms.

\item[Discussion and Conclusions] summarizes current status, what
remains to be done, and lessons learned. \oops{Not yet it doesn't}

\end{description}

\oops{Where to put problems with event-loops, and persistence
  enables watchdogs + rollback}

\section{The Sequential \abst{StatusHolder}}

Throughout the paper, we will revisit various elaborations of the
listener pattern \cite{Englander:beans}. The following code is
representative of the basic sequential listener pattern.\footnote{
%
The listener pattern \cite{Englander:beans} is similar to the observer
pattern \cite{gamma:patterns}. However, the analysis which follows
would be quite different if we were starting from the observer
pattern.}
%
In it, a \abst{statusHolder} object is used to coordinate a changing
status between \emph{publishers} and \emph{subscribers}.  A subscriber
can ask for the current status of a \abst{statusHolder} by calling
\meth{getStatus}, or can subscribe to receive notifications when the
status changes by calling \meth{addListener} with a listener object.
A publisher changes the status in a \abst{statusHolder} by calling
\meth{setStatus} with the new value.  This in turn will call
\meth{statusChanged} on all subscribed listeners.  In this way,
publishers can communicate updates of a particular status to
subscribers without knowing of each individual subscriber.
%
\begin{figure}
\begin{alltt}
    public class \cls{StatusHolder} \{
        private Object \dvar{myStatus};
        private final ArrayList<Listener> \dvar{myListeners} 
                          = new ArrayList();

        public \dmeth{StatusHolder}(Object \dvar{status}) \{
            myStatus = status;
        \}
        public void \dmeth{addListener}(Listener \dvar{newListener}) \{
            myListeners.add(newListener);
        \}
        public Object \dmeth{getStatus}() \{
            return myStatus; 
        \}
        public void \dmeth{setStatus}(Object \dvar{newStatus}) \{
            myStatus = newStatus;
            for (Listener \dvar{listener}: myListeners) \{
                listener.statusChanged(newStatus);
            \}
        \}
    \}
\end{alltt}
\end{figure}
%
We can use this pattern to coordinate several loosely coupled
plans. For example, in a simple application, a bank account
manager publishes a bank account balance to an analysis spreadsheet
and a financial application.  Deposits and withdrawals cause a new
balance to be published.  The spreadsheet adds a listener that will
update the display to show the current balance. The finance
application adds a listener to begin trading activities when the
balance falls below some threshold.  Although the plans represented by
these clients interact cooperatively, they know very little about each
other, and should be able to proceed independently without
interference from each other.  

\oops{Suggested replacement: 
We can use this pattern to coordinate several loosely coupled
plans. As a concrete example, imagine a StatusHolder named
\var{balance} that holds the balance of a bank account. Among its
clients are \var{manager}, an account manager, \var{protector}, an
overdraft protector, and \var{display}, a display.  \var{manager}
publishes a new balance in reaction to deposits and
withdrawals. \var{protector} subscribes a listener in order to react
when the balance falls below a threshold. \var{display} subscribes a
listener in order to update a display showing the current balance.
Although these clients interact cooperatively, they know very little
about each other.
}

Even under sequential and benign conditions, the listener pattern in
the \abst{statusHolder} creates plan interference hazards programmers
must beware of \oops{suggested replacement: against which programmers
  must defend}.
%
\begin{description}

\item[Aborting the wrong plan:] 

If a listener throws an exception, this prevents some other listeners
from being notified of the new status and possibly aborts the
publisher's plan. In the above example, the spreadsheet's inability to
display the new balance should not impact either the finance
application or the bank account manager.

\item[Nested subscription:] 

The actions of a listener could cause a new listener to be subscribed.
For example, to bring a lowered balance back up, the finance
application might initiate a stock trade operation, which adds its own
listener.  Whether that new listener sees the current event, fails to
see the current event, or fails to be subscribed depends on minor
details of the listener implementation.

\item[Nested publication:] 

Similarly, a listener may cause a publisher to publish a new status,
possibly unknowingly due to aliasing.  For example, during an update,
the invocation of \meth{setStatus} notifies the finance application, which
deposits money into the account. A new update to the balance is
published and an inner invocation of \meth{setStatus} notifies all listeners
of the new balance.  After that inner invocation returns, the outer
invocation of \meth{setStatus} continues notifying listeners of the older,
pre-deposit balance.  Some of the listeners would receive the
notifications \emph{out of order}.  As a result, the spreadsheet might
leave the display showing the wrong balance, or worse, the finance
application might initiate transactions based on incorrect
information.

\end{description}
%
The nested publication hazard is especially striking because it
reveals that problems typically associated with concurrency may arise
even in a simple sequential example. This is why we draw attention to
\emph{plans}, rather than programs or processes.

The \abst{statusHolder}, by running each subscriber's plan during a
step of a publisher's plan, has provoked plan interference: these
largely independent plans now interact in surprising ways, creating
numerous new cases that are difficult to identify, prevent, or
test. Nonetheless, for cases in which the subscribers are unlikely to
interact with each other (e.g., they are different graphical widgets),
under sequential and benign conditions, experienced programmers
regularly use the listener pattern successfully.

\oops{Suggested replacement:
Although these hazards are real, experience suggests that programmers
can usually find ways to avoid them in sequential programs under
benign conditions.
}

\section{Why Not Shared-state Concurrency}

With genuine concurrency, interacting plans unfold in parallel. To
manipulate state and preserve consistency, a plan needs to ensure
others aren't manipulating that same state at the same time. This
section explores the plan coordination problem in the context of the
conventional shared-state concurrency-control paradigm
\cite{VanRoyHaridi}; also known as shared-memory multi-threading. We
present several attempts at a conventionally \emph{thread-safe}
\abst{statusHolder}---searching for one that prevents its clients from
interfering without preventing them from
cooperating. \oops{consistency/safety vs. progress/liveness}

In the absence of real-time concerns, we can analyze concurrency
without thinking about genuine parallelism. Instead, we can normally
model the effects of concurrency as the non-deterministic interleaving
of atomic units of operation. We can roughly characterize a
concurrency-control paradigm with the answers to two questions.
%
\begin{description}

\item[Serializability:] 

What are the coarsest-grain units of operation, such that we can
account for all visible effects of concurrency as equivalent to some
fully-ordered interleaving of these units \cite{IBM:POO}? For
shared-state concurrency, this unit is generally no larger than a
memory access, instruction, or system call---which is often finer than
the ``primitives'' provided by our programming languages
\cite{boehm:threads}. For databases, this unit is the transaction.

\item[Mutual exclusion:]

What mechanisms can eliminate the possibility of some interleavings,
so as to preclude the hazards associated with them? For shared-state
concurrency, the two dominant answers are monitors
\cite{hoare:monitors,hansen:monitors}, and rendezvous
\cite{hoare:csp}. For distributed programming, many systems restrict
the orders in which messages may be delivered
\cite{birman:vsync,amir:thesis,lamport:paxos}.

\end{description}
%
\sys{Java} is loosely in the monitor tradition. \sys{Ada},
\sys{Concurrent ML}, and the synchronous $\pi$-calculus are loosely in
the rendezvous tradition. With minor adjustments, the following
comments apply to both.

\subsection{Preserving Consistency}

If we place our sequential \abst{statusHolder} into a concurrent
environment, it may get called simultaneously from publishers or
subscribers in different threads. The resulting interleaving of
operations, might, for example, mutate the \var{myListeners} list
while the for-loop is in progress.

\begin{figure}
\centerline{\epsfig{figure=seesaw.eps}}
\caption{A correct program must both remain consistent and continue to
make progress. The sequence above represents our search for a
\abst{statusHolder} which supports both well:
(1) The sequential \abst{statusHolder}. 
(2) The sequential \abst{statusHolder} in a concurrent environment.
(3) The fully-synchronized \abst{statusHolder}.
(4) Placing the for-loop outside the synchronized block.
(5) Spawning a new thread per listener notification.
(6) Using communicating event loops}
\label{fig:seesaw}
\end{figure}

Adding the ``\code{synchronized}'' keyword to all methods of the above
code causes it to resemble a monitor. This fully-synchronized
\abst{statusHolder} eliminates exactly those cases where two plans
interleave within the \abst{statusHolder}. It is as good at preserving
its own consistency as our original sequential \abst{statusHolder}
was.

However, it is generally recommended that \sys{Java} programmers avoid
this fully-synchronized pattern because it is prone to deadlock
\cite{Englander:beans}. Although each listener is called from some
publisher's thread, its purpose may be to contribute to a plan
unfolding in its subscriber's thread. To defend itself against such
concurrent entry, the objects at this boundary may themselves be
synchronized. If a \meth{statusChanged} notification gets blocked
here, waiting on that subscriber's thread, it blocks the
\abst{statusHolder}, as well as any other objects whose locks are held
by that publisher's thread. If the subscriber's thread is itself
waiting on one of these objects, we have a classic deadly embrace.

Although we have eliminated interleavings that lead to inconsistency,
some of the interleavings we eliminated were necessary to make
progress.

\subsection{Avoiding Deadlock}

To avoid this problem, \cite{Englander:beans} recommends changing the
\meth{setStatus} method to clone the listeners list within the
synchronized block, and then to exit the block before entering the
for-loop:
%
\begin{alltt}
    public void \dmeth{setStatus}(Object \dvar{newStatus}) \{
        ArrayList<Listener> \dvar{listeners};
        synchronized (this) \{
            myStatus = newStatus;
            listeners = (ArrayList<Listener>) myListeners.clone();
        \}
        for (Listener \dvar{listener}: listeners) \{
            listener.statusChanged(newStatus);
        \}
    \}
\end{alltt}
%
This code avoids holding a lock during notification, and thus avoids
the obvious deadlock described above between a publisher and a
subscriber.  It does not avoid the underlying hazard, however, because
the publisher may hold other locks.  For example, if the bank account
manager holds a lock on the bank account during a withdrawal, a
deposit attempt by the finance application thread as a result of the
notification may result in an equivalent deadlock, with the account
manager waiting for the notification of the finance application to
complete, and the finance application waiting for the account to
unlock.  The result is that all the associated objects are locked, and
other subscribers will never hear about this update.  Thus, the
underlying hazard remains.

In this approach, some interleavings needed for progress are still
prevented, and as we will see, some newly allowed interleavings lead
to inconsistency.

\subsection{Race Conditions} 

The approach above has a consistency hazard: if \meth{setStatus} is
called from two threads, the order in which they update \var{myStatus}
will be the order they enter the synchronized block above. However,
the for-loop notifying listeners of a later status may race ahead of
one that will notify them of an earlier status. As a result, even a
single subscriber may see updates out of order, so the spreadsheet may
leave the display showing the wrong balance, even in the absence of
any nested publication.

It is possible to adjust for these remaining problems. The style
recommended for some rendezvous-based languages, like \sys{Concurrent
ML} and the $\pi$-calculus, corresponds to spawning a separate thread
to perform each notification.  This avoids using the producer's thread
to notify the subscribers, and thus avoids the deadlock
hazard---allowing all interleavings needed for progress. However, this
style still suffers from the same race condition hazards, and so still
fails to eliminate enough interleavings. We could compensate for this
by adding a counter to the \abst{statusHolder} and to the notification
API, and by modifying the logic of all listeners to reorder
notifications. But a formerly trivial pattern has now exploded into a
case-analysis minefield. Actual systems contain thousands of patterns
more complex than our \abst{statusHolder}. Some of these will suffer
from less obvious minefields.
%
\begin{quotation}
This is ``Multi-Threaded Hell''. As your application evolves, or as
different programmers encounter the sporadic and non-reproducible
corruption or deadlock bugs, they will add or remove locks around
different data structures, causing your code base to veer back and
forth \ldots, erring first on the side of more deadlocking, and then
on the side of more corruption. This kind of thrashing is bad for the
quality of the code, bad for the forward progress of the project, and
bad for morale.
\begin{flushright}
---An experience report from the development of Mojo Nation \cite{zooko:hell}
\end{flushright}
\end{quotation}

\section{A Taste of E}

Before revisiting the issues above, let's first use this example to
briefly explain E as a sequential object language. (For a more
complete explanation of E, see \cite{stiegler:ewalnut}.)  Here is the
same \abst{statusHolder} as defined in E.
%
\begin{alltt}
    def \dobj{makeStatusHolder}(var \dvar{myStatus}) \{
        def \dvar{myListeners} := [].diverge()
        def \dobj{statusHolder} \{
            to \dmeth{addListener}(\dvar{newListener}) \{
                myListeners.push(newListener)
            \}
            to \dmeth{getStatus}() \{ return myStatus \}
            to \dmeth{setStatus}(\dvar{newStatus}) \{
                myStatus := newStatus
                for \dvar{listener} in myListeners \{
                    listener.statusChanged(newStatus)
                \}
            \}
        \}
        return statusHolder
    \}
\end{alltt}
%
E has no classes. Instead, the expression beginning with ``\code{def
\dobj{statusHolder}}'' is an object definition expression. It creates
a new object with the enclosed method definitions, and binds the new
\var{statusHolder} variable to this object. An invocation, such as
``\code{statusHolder.setStatus(33)}'', causes a message to be
delivered to an object. When an object receives a message, it reacts
according to the code of its matching method. As with \sys{Smalltalk}
\cite{goldberg:purplebook} or \sys{Actors} \cite{hewitt:actors}, all
values are objects, and all computation proceeds only by delivering
messages to objects.

From a $\lambda$-calculus perspective, an object definition expression
is a lambda expression, in which the (implicit) parameter is bound to
the incoming message, and the body selects a method to run according
to the message. The delivery of a message to an object is the
application of an object-as-closure to a message-as-argument. An
object's behavior is indeed a function of the message it is applied
to. This view of objects goes back to \sys{Smalltalk-72}
\cite{goldberg:smalltalk72} and \sys{Actors}, and is hinted at earlier
in \cite{hoare65}. Also see \cite{shroff:match}.

Unlike a class definition, an object definition does not declare its
instance variables. Instead, the instance variables of an object are
simply the variables used freely within the object definition (which
therefore must be defined in some lexically enclosing scope). The
instance variables of \abst{statusHolder} are \var{myStatus} and
\var{myListeners}.  Variables are unassignable by default; the
``\code{var}'' keyword defines \var{myStatus} as an assignable
variable. Square brackets evaluate to an immutable list containing the
values of the subexpressions (the empty-list in the example). Lists
respond to the ``\code{diverge()}'' message by returning a new mutable
list whose initial contents are a snapshot of the diverged list. Thus,
\var{myListeners} is initialized to a new, empty, mutable list, which
acts much like an \cls{ArrayList}.

\sys{E} provides syntactic shorthands to use objects that define a
``\meth{run}'' method as if they were functions.The syntax for
\var{makeStatusHolder} is a shorthand for defining an object with a
single ``\meth{run}'' method. It expands to:
%
\begin{alltt}
    def \dobj{makeStatusHolder} \{
        to \dmeth{run}(var \dvar{myStatus}) \{
            # ...
\end{alltt}
%
The corresponding function call syntax,
``\code{makeStatusHolder(44)}'', is shorthand which expands to
``\code{makeStatusHolder.run(44)}''. Each time \var{makeStatusHolder} is
called, it defines and returns a new \abst{statusHolder}.

\subsection{Two Ways to Postpone Plans}

The E code for \abst{statusHolder} above retains the simplicity and
hazards of the sequential Java version.  To address these hazards
requires examining the underlying issues.  When the
\abst{statusHolder}---or any agent---is executing plan $X$, and
discovers the need to engage in plan $Y$, in a sequential system, it
has two simple choices of when to do $Y$:
%
\begin{description}

\item[Immediately:] Put $X$ aside, work on $Y$ until
complete, then go back to $X$.

\item[Eventually:] Put $Y$ on a ``to-do'' list, and work on it
when $X$ is complete.

\end{description}
%
The ``immediate'' option corresponds to conventional sequential
call-return control flow (or strict applicative-order evaluation), and
is represented by the ``\code{.}'' or \emph{immediate-call} operator,
which delivers the message immediately. Above, \abst{statusHolder}'s
\meth{addListener} method tells \var{myListeners} to push the
\var{newListener} \emph{now}. When \meth{addListener} proceeds past
this point, it may assume that all the side effects it requested are
done.

For the \abst{statusHolder} example, all of the sequential hazards
(e.g., Nested Publication) and many of the concurrent hazards
(deadlock) occur because the \meth{statusChanged} method is also
invoked immediately: the publisher's plan is set aside to pursue the
listener's plan (which might then abort, change the state further,
etc.).

The ``eventual'' option corresponds to the human notion of a ``to-do''
list: the item is queued for later execution. E provides direct
support for this asynchronous messaging option, represented by the
``\code{<-}'' or \emph{eventual-send} operator.

Using eventual-send, the \meth{setStatus} method can ensure that
each listener will be notified of the changed status in such a way
that it does not interfere with the \abst{statusHolder}'s current
plan.  To accomplish this in E, the \meth{setStatus} method becomes:
%
\begin{alltt}
    to \dmeth{setStatus}(\dvar{newStatus}) \{
        myStatus := newStatus
        for \dvar{listener} in myListeners \{
            listener <- statusChanged(newStatus)
        \}
    \}
\end{alltt}
%
As a result of using eventual-send above, all of the sequential
hazards are addressed: errors, new subscriptions, and additional
status changes caused by listeners will all take place after all
notifications for a published event have been scheduled.  The
publishers' plans and the subscribers' plans are \emph{temporally
isolated}---so these plans may unfold with fewer unintended
interactions. For example, it can no longer matter whether the
assignment to \var{myStatus} happens before or after the for-loop.

\subsection{Simple E Execution}

This section describes how temporal isolation is achieved within a
single thread of control.  The next section describes how it is
achieved in the face of concurrency and distribution.

\begin{figure}
\centerline{\epsfig{figure=big1vat.eps}}
\caption{An E vat consists of a heap of objects and a thread of
  control. The stack and queue together record the postponed plans the
  thread needs to process. An immediate-call pushes a new frame on top
  of the stack, representing the delivery of a message ({\it arrow})
  to a target object ({\it dot}). An eventual-send enqueues a new
  pending delivery on the right end of the queue. The thread proceeds
  from top to bottom and then from left to right.
%
\oops{Dean, call me. I reverted from your: An E vat.  The bottom of
the call-return stack is the active delivery. An eventual-send appends
a new pending delivery to the queue.}}
\label{fig:stackvat}
\end{figure}

In E, an eventual-send creates and queues a \emph{pending delivery},
which represents the eventual delivery of a particular message to a
particular object.  Within a single thread of control, the E runtime
has both a normal execution stack for immediate call-return and a
queue containing all the pending deliveries.  Execution proceeds by
taking a pending-delivery from the queue, delivering its message to
its object, and processing all the resulting immediate-calls in
conventional call-return order.  This is called a \emph{turn}.  When a
pending delivery completes, the next one is dequeued, and so forth.
This is the classic event-loop model, in which all of the events are
pending deliveries. Because each event's turn runs to completion
before the next is serviced, they are temporally isolated.

Additional mechanisms to process results and exceptions from
eventual-sends will be discussed in further sections below.

The combination of a stack, a pending delivery queue, and the heap of
objects they operate on is called a \emph{vat}.  Each E object lives
in exactly one vat, and a vat may host many objects.  Each vat lives
on one machine at a time, and a machine may host many vats. The vat is
also the minimum unit of persistence, migration, partial failure,
resource control, and defense from denial of service. We'll return to
some of these topics below.

\section{Communicating Event Loops}

We now consider the case where our account (including account manager
and its \abst{statusHolder}) runs in \vat{A} on one machine, and our
spreadsheet (including its listener) runs in \vat{S} on another
machine.

In E, we distinguish several reference-states. A direct reference
between two objects in the same vat is a \emph{near
reference}.\footnote{
%
For brevity, we generally do not distinguish a near reference from the
object it designates.}
%
As we've seen, near references carry both immediate-calls and
eventual-sends. Only \emph{eventual references} may cross vat
boundaries, so the spreadsheet holds an eventual reference to the
\abst{statusHolder}, which in turns holds an eventual reference to the
spreadsheet's listener. Eventual references are first class---they can
be passed as arguments, returned as results, and stored in data
structures, just like near references. However, eventual references
can carry only eventual-sends, not immediate-calls (i.e., an
immediate-call on an eventual reference throws an exception). This
constraint is compatible with \abst{statusHolder}'s code above, since
it stores, retrieves, and eventual-sends to its listeners, but never
immediate-calls them.  Figure~\ref{fig:2vat} shows what happens when a
message is sent between vats.

\begin{figure}
\centerline{\epsfig{figure=big2vat.eps,width=340pt}}
\caption{If the account manager and the spreadsheet are in separate
  vats, when the account manager (1) tells the \abst{statusHolder}
  which represents its balance to immediately update, this (2)
  transfers control to the \abst{statusHolder}, which (3) notes that
  its listeners should eventually be notified. The message is (4) sent
  to the spreadsheet's vat, which queues it on arrival, and eventually
  (5) delivers it to the listener, which updates the display of the
  spreadsheet cell}
\label{fig:2vat}
\end{figure}

When the \abst{statusHolder} in \vat{A} performs an eventual-send of
the \meth{statusChanged} message to the spreadsheet's listener in
\vat{S}, \vat{A} creates a pending delivery as before, recording the
need to deliver this message to this listener. Pending deliveries need
to be queued on the pending delivery queue (i.e., the to-do list)
of the vat hosting the object that will receive the message---in this
case, \vat{S}. \vat{A} serializes (marshals) the pending delivery onto
an encrypted, order-preserving byte stream read by \vat{S}. Should it
ever arrive at \vat{S}, \vat{S} will unserialize it and queue it on
its own pending delivery queue.

Since each vat runs concurrently with all other vats, turns in
different vats no longer have actual temporal isolation. If \vat{S} is
otherwise idle, it may service this delivery, notifying the
spreadhseet's listener of the new balance, while the original turn is
still in progress in \vat{A}. But so what? These two turns can only
execute simultaneously when they are in different vats. In this case,
the spreadsheet cannot affect the account manager's
turn-in-progress. Because only eventual references span between vats,
the spreasheet can only affect \vat{A} by eventual-sending to objects
hosted by \vat{A}. This cannot affect any turn already in progress in
\vat{A}---\vat{A} only queues the pending delivery, and will service
it sometime after the current turn, and turns for previously queued
pending deliveries, complete.

Only near references provide one object synchronous access to
another. Therefore an object only has synchronous access to state
within its own vat. Taken together, these rules guarantee that a
running turn---a sequential call-return program---implicitly has
mutually exclusive access to everything to which it has synchronous
access. In the absence of real-time concerns, this provides all the
isolation that was achieved by temporal isolation in the
single-threaded case.

The net effect is that a turn is E's unit of operation. We can
faithfully account for the visible effects of concurrency without any
interleaving of the steps within a turn. Any actual multi-vat
computation is equivalent to some fully-ordered interleaving of
turns.\footnote{
%
An E turn may never terminate, which is hard to account for within
this simple model of serializability. There are formal models of
asynchronous systems that can account for non-terminating events
\cite{chandy:snapshots}. Within the scope of this paper, we can safely
ignore this issue.}
%
As with database transactions, the length of an E turn is not
predetermined. It is a tradeoff left for the developer to decide. How
the object graph is carved up into vats and how computation is carved
up into turns will determine which interleaving cases are eliminated,
and which must be handled explicitly by the programmer.

Because E has no explicit locking constructs, computation within a
turn can never block---it can only run, to completion or
forever.\footnote{
%
The actual E system does provide synchronous file I/O operations. When
these files are local, prompt, and private to the vat accessing them,
this does not violate turn isolation. But since files may be remote,
non-prompt, or shared, the availability of these synchronous I/O
operations does violate the E model.}
%
A vat as a whole is either processing pending deliveries, or is idle
when there are no pending deliveries to service. Because computation
never blocks, it cannot deadlock.  Other lost progress hazards are
discussed in the section on ``Datalock'' below.

\section{Mutual Suspicion}

When using a language that supports shared-state concurrency, one can
choose to avoid it and adopt the event-loop style instead. Indeed,
several \sys{Java} libraries, such as \sys{AWT}, were initially
designed to be thread-safe, and were then re-designed around
event-loops. Using event-loops, one can easily write a \sys{Java}
class equivalent to our \var{makeStatusHolder}.  If one can so easily
choose to avoid shared-state concurrency, does E actually need to
prohibit it? The question leads us to examine \oops{motivates an
examination of} how mutual suspicion affects the definition of program
correctness.

E uses the event-loop approach to simplify the task of preserving
consistency while maintaining progress. Preserving consistency stays
simple for the \abst{statusHolder} only if it executes in at most one
thread at a time.  As we discussed previously, the possibility of
multiple threads would necessitate complex locking. Preserving
consistency stays simple \emph{only} if the \abst{statusHolder} has no
more than one thread executing in it at a time.  If one of its clients
\emph{could} create a new thread and call it, then the simple version
of the \abst{statusHolder} could not preserve consistency (i.e., it
would need to perform the complex locking mentioned in the previous
section). The introduction of multiple threads is just one of the ways
in which a client could potentially compromise the consistency of an
object.

\oops{need a better transition?}

\subsection{Defensive Correctness}

If a user browsing a webserver were able to cause incorrect pages to
be displayed to other users, we would likely consider it a bug in the
webserver---we expect it to remain correct regardless of the client's
behavior.  We call this property \emph{defensive correctness}: a
program \name{P} is defensively correct if it remains correct despite
arbitrary behavior on the part of its clients.  Before this definition
can be useful, we need to pin down what we mean by ``arbitrary''
behavior.

When we say that a program \name{P} is correct, this normally means
that we have a specification in mind, and that \name{P} behaves
according to that specification.  There are some implicit caveats in
that assertion, however. For example, \name{P} cannot behave at all
unless it is run on a machine; if the machine operates incorrectly,
\name{P} on that machine may behave in ways that deviate from its
specification.  

We do not consider this to be a bug in \name{P}, because \name{P}'s
correctness implicitly depends on the machine's correctness.  If
\name{P}'s correctness depends on another component \name{Q}'s
correctness, we will say that \name{P} \emph{relies upon} \name{Q}.
For example, a typical webserver relies on the underlying machine and
on operating system features such as files and sockets.  We will refer
to the set of all elements on which \name{P} relies as \name{P}'s
\emph{reliance set}.\footnote{
%
     The set of all things that \name{P} relies on is similar in
     concept to \name{P}'s ``Trusted Computing Base'' or TCB. ``Rely''
     articulates the objective situation (\name{P} is vulnerable to
     \name{Q}), and so avoids confusions engendered by the word
     ``trust''.}

We define \name{Q}'s \emph{authority} as the set of effects \name{Q}
could cause.  With regard to \name{P}'s correctness, \name{Q}'s
\emph{relevant authority} is bounded by the the assumption that
everything in \name{P}'s reliance set is correct, since \name{P} was
defined under this assumption. For example, if a user could cause a
webserver to show the wrong page to other browsers by replacing a
file through an OS exploit, then the underlying operating system would
be incorrect, not the webserver. We say that \name{P} \emph{protects
against} \name{Q} if \name{P} remains correct despite any possible
actions by \name{Q}, assuming the correctness of \name{P}'s reliance
set.

\oops{We never talked about suspicion. How about....
%
If \name{P} and \name{Q} represent independent plans representing
different interests, ``suspicion'' refers to their desire to proceed
without interference from each other.  They cannot distinguish
inconvenient plan interference from malicious sabotage.  
}

Now we can speak more precisely about defensive correctness. The
"arbitrary behavior" mentioned earlier is the combined relevant
authority of a program's clients. \name{P} is \emph{defensively
correct} if it protects against all of its clients.

\oops{Could use a better example, because some servers might try to
prevent exactly that - they have a hash somewhere to detect a file
replacement.  We could use this as an example of the
programmer needing to decide which assumptions are appropriate.

possible: A program could be coded to protect against components
that it uses, not just clients.  For example, the webserver above
could keep a separate hash of each file, and check that the file
contents were unchanged before displaying it to the user.}

Defensive correctness requires protecting against \emph{clients} in
particular in order to enable the composition of correct components
into larger correct systems. If \name{P} relies on \name{R}, then
\name{P} also relies on all of \name{R}'s other clients \emph{unless}
\name{R} is defensively correct.  If \name{R} does not protect against
its other clients, \name{P} cannot prevent them from interfering with
its own plan, which makes it infeasible for \name{P} to ensure its own
correctness.  By not relying on its clients, \name{R} enables them
to avoid relying on each other.

This explains why it is important for E to forbid the spawning of
threads.  As we saw earlier, it can be very difficult to write
programs in which threads protect against each other.  Removing
threads eliminates a key obstacle to defensive correctness.

\subsection{Defensive Consistency}

Correctness can be divided into consistency (safety) and progress
(liveness). An object that is vulnerable to denial-of-service by its
clients may nevertheless be \emph{defensively consistent}. Given that
all the objects it relies on themselves remain consistent, a
defensively consistent object will never give incorrect service to
well-behaved clients, but it may be prevented from giving them any
service. A defensively correct object is invulnerable to its
clients. A defensively consistent object is merely incorruptible by
its clients.

Different security properties are feasible at different
granularities. Some conventional operating systems attempt to provide
support for protecting users from each other's misbehavior. But
because programs are normally run with their user's full authority,
all software that is run under the same account is mutually
reliant: Since each is granted the authority to corrupt the others via
underlying components on which they all rely, they cannot usefully
protect against such ``friendly fire''.\footnote{
%
See \cite{stiegler:polaris} for an unconventional way to use
conventional OSes to provide greater security.}
%
Some operating systems designs \cite{dvh} support defensive
consistency at the process granularity. Others, by providing
principled controls over computational resource rights
\cite{hardy:keykos,shapiro:eros}, can also protect against denial of
service. Among machines distributed over today's Internet,
cryptographic protocols help support defensive consistency, but
defensive correctness remains infeasible.

In most programming languages, all objects in the same process are
mutually reliant. A secure language is one which supports some useful
form of protections within a process.  Among objects in the same vat,
E supports defensive consistency: Any object may go into an infinite
loop, thereby preventing the progress of all other objects within
their vat. Therefore, within E's architecture, defensive correctness
\emph{within} a vat is impossible. With respect to progress, all
objects within the same vat are mutually reliant. In many situations,
defensive consistency is adequate---a potential adversary often has
more to gain from corruption than denial of service. This is
especially so in iterated relationships, since corruption may
misdirect plans but go undetected, while loss of progress is quite
noticeable.

\oops{for the above: The vat is the minimum unit of full defensive
correctness, as will be discussed below.}

\subsection{Principle of Least Authority (POLA)}

Our \abst{statusHolder} itself is now defensively consistent, but is
it a good abstraction for the account manager to rely on to build its
own defensively consistent plans? In our example scenario, we have
been assuming that the account manager acts only as a publisher, and
that the finance application and spreadsheet act only as
subscribers. However either subscriber \emph{could} invoke the
\meth{setStatus} method. If the finance application calls
\meth{setStatus} with a bogus balance, the spreadsheet will dutifully
render it.

This is a problem of access control. The \abst{statusHolder}, by
bundling two kinds of authority into one object, encouraged patterns
where both kinds of authority were provided to objects that only
needed one. This can be addressed by grouping these methods into
separate objects, each of which represents a sensible bundle of
authority.
%
\begin{alltt}
    def \dobj{makeStatusPair}(var \dvar{myStatus}) \{
        def \dvar{myListeners} := [].diverge()
        def \dobj{statusGetter} \{
            to \dmeth{addListener}(\dvar{newListener}) \{
                myListeners.push(newListener)
            \}
            to \dmeth{getStatus}() \{ return myStatus \}
        \}
        def \dobj{statusSetter} \{
            to \dmeth{setStatus}(\dvar{newStatus}) \{
                myStatus := newStatus
                for \dvar{listener} in myListeners \{
                    listener <- valueChanged(newStatus)
                \}
            \}
        \}
        return [statusGetter, statusSetter]
    \}
\end{alltt}
%
Now the account manager can make use of \var{makeStatusPair} as
follows:
%
\begin{alltt}
    def [\dvar{sGetter}, \dvar{sSetter}] := makeStatusPair(33)
\end{alltt}
%
The call to \var{makeStatusPair} on the right side makes four
objects---an object representing the \var{myStatus} variable, a
mutable \var{myListeners} list, a \var{statusGetter}, and a
\var{statusSetter}. The last two each share access to the first
two. The call to \var{makeStatusPair} returns a list holding these
last two objects. The left side pattern-matches this list, binding
\var{sGetter} to the new \var{statusGetter}, and binding \var{sSetter}
to the new \var{statusSetter}.

The account manager can now keep the new \var{statusSetter} for
itself, and give the spreadsheet and the finance application access
only to the new \var{statusGetter}. More generally, we may now
describe publishers as those with access to \var{statusSetter} and
subscribers as those with access to \var{statusGetter}. The account
manager can now provide consistent balance reports to all of its
clients, because it has denied to its clients the possibilities that
would have enabled them to corrupt this service. Because it can
provide defensive consistency, its clients can now rely on it without
relying on each other.

As with concurrency control, the key to access control is to allow
enough possibilities without allowing too many. We wish to provide
objects the authority needed to carry out their proper
duties---publishers gotta publish---but little more. This is known as
\emph{POLA}, the \emph{Principle of Least Authority} (See
\cite{miller:paradigm} for the relationship between POLA and the
Principle of Least Privilege \cite{SaltzerSc75}). By not granting its
subscribers the authority to publish a bogus balance, the account
manager no longer needs to worry about what would happen if they
did. This discipline helps us design patterns of plan composition in
which well-intentioned plans can successfully cooperate, while
limiting the cases of malicious plan interference we need
consider. \oops{suggested: This discipline helps us compose plans so
as to allow well-intentioned plans to successfully co-operate, while
minimizing the kinds of plan interference against which we must
defend.}

\oops{the above sentence doesn't quite parse and isn't parallel}

\section{A Taste of E on a Network}

\oops{this should be integrated with the *next* section}

E's computational model straightforwardly extends across the network.
For example, an eventual reference in a vat can refer to an object in
a vat on another machine, and eventual-sends to that reference are
sent across an encrypted link and posted as pending deliveries for the
referenced object on the remote vat.  

The network protocol, \sys{Pluribus}, actually runs between vats, not
between machines. Therefore, we can ignore the distinction between vats
and machines, without loss of generality. An incorrect machine is,
from our perspective, simply a set of incorrect vats; i.e., vats that
do not implement the language and/or protocol correctly.

In addition, \sys{Pluribus} is designed to enforce characteristics of
the E computational model, such as reference integrity, so that E
programs can rely on those properties between vats, and therefore
between machines. For example, while objects within another vat could
collude and act arbitrarily within the union of their authorities,
they cannot feasibly\footnote{
%
\sys{Pluribus} relies on the standard cryptographic assumptions that
large random numbers are not feasibly guessable, and that well
accepted algorithms are immune to feasible cryptanalysis.}
%
manufacture new authorities. Thus, if an object relies on another
object in a remote vat, then it also relies on that remote vat
(because the remote object relies on it).

Finally, the remote object and vat could even be implemented in a
different language entirely, and a local vat could still view it from
a correctness point of view as a (possibly incorrect) program written
in E.  The details of \sys{Pluribus}, however, are beyond the scope of
this document.

\oops{do we need to point out much earlier that ``relies'' is usually
often (but not always) transitive?}

\section{Promise Pipelining}

The concurrency-control examples so far have been artificially
simple. The eventual-send examples were carefully selected to be
evaluated only for their effects, with no use made of the value of
these expressions. In normal message-sending, a subgoal often returns a
value to its caller, for its caller to use in executing the remainder
of its plan. We use this feature pervasively for functional
composition, as in the following code fragment:
%
\begin{alltt}
    def \dvar{r3} := x.a().c(y.b())
\end{alltt}
%
which is equivalent to:
%
\begin{alltt}
    def \dvar{r1} := x.a() 
    def \dvar{r2} := y.b() 
    def \dvar{r3} := r1.c(r2)
\end{alltt}
%
For this to be a correctly formulated plan, the object executing this
plan, \name{W}, must know that the objects designated by its \var{x}
and \var{y} variables, \name{X} and \name{Y}, are co-located with it,
so that \var{x} and \var{y} hold near references, and it must know
that the results they will return in response to the ``\code{a()}''
and ``\code{b()}'' requests will also be near. Returning to our
analogy, \oops{analogy got lost} when you know you've already arranged
to have in your immediate reach everything you need to execute the
subgoal, then you can use subgoal stacking successfully. Much of the
art of concurrency control in E is to make such arrangements, so that
you can take substantial steps within the isolation provided by an
individual turn.

But what if you need to formulate a plan that needs to work whether
these objects are local or remote? In our analogy, \oops{analogy got
lost} at some point in your plan, you need to ask Carol for
something, but she may not get back to you for awhile. Part of your
plan needs to be postponed, waiting for her, but you continue with
your life (advancing other plans) in the meantime.

\subsection{Promises}

For example, suppose \name{W} resides on \vat{W} and \name{X} and
\name{Y} are on \vat{X}. \name{W}'s variables \var{x} and \var{y} will
then hold eventual references, which allow \name{W} only to
eventual-send messages to \name{X} and \name{Y}. Suppose \name{W}
executes:
%
\begin{alltt}
    def \dvar{r1} := x <- a()
\end{alltt}
%
As before, once the pending delivery---representing the need to
deliver this message to this receiver---is serialized and
queued to be sent to \vat{X}, the ongoing turn in \vat{W} continues
without waiting on the network or other vats. In this case, the value
bound to \var{r1} is a reference to the outcome of this delivery, even
though the delivery hasn't happened yet. We say that \var{r1} holds a
\emph{promise} for the outcome. The pending delivery sent to \vat{X}
additionally contains a \emph{resolver} for this promise, which
provides the right to choose what \var{r1} designates. In \vat{X},
once the turn spawned by delivering \code{a()} to X completes, \vat{X}
reports the outcome to the resolver, \emph{resolving} the promise, so
that \var{r1} eventually becomes a reference designating this
outcome. The kind of reference that \var{r1} eventually becomes
depends on this outcome.

Until this promise is resolved, what kind of a reference is it? Since
\vat{W} does not yet know what \var{r1} designates, \name{W} cannot
immediate-call it, so clearly a promise is not a near reference. But
\name{W} can eventual-send messages to \var{r1}, since \var{r1} will
eventually be resolved.  Thus, a promise is another kind of eventual
reference. Since the requests sent to \var{r1} cannot be delivered
until the promise is resolved, these requests are buffered, in FIFO
order, within the promise. Once the promise is resolved, these
messages are forwarded, in order, to its resolution.

\subsection{Pipelining}

Since \name{W} can eventual-send to the promises resulting from
previous eventual-sends, \name{W} can still engage in functional
composition. If \name{W} executes
%
\begin{alltt}
    def \dvar{r3} := (x <- a()) <- c(y <- b())
\end{alltt}
%
or equivalently
%
\begin{alltt}
    def \dvar{r1} := x <- a()
    def \dvar{r2} := y <- b()
    def \dvar{r3} := r1 <- c(r2)
\end{alltt}
%
all three requests are serialized and streamed out to \vat{X}
immediately, and \vat{W} continues without blocking. (By contrast, in
a conventional RPC system
\cite{Nelson81,java:rmi,corba:latency,xml-rpc:latency}, the calling
thread would only proceed after two or three round trips---depending
on whether \code{a()} and \code{b()} are overlapped.)

\begin{figure}
\centerline{\epsfig{figure=pipeline-only.eps}}
\caption{These three messages are streamed out together, with no round
  trip. Each message box ``rides'' on the reference it is sent
  on. References \var{x} and \var{y} are shown with solid arrowheads,
  indicating that their target is known. The others are
  \emph{promises}, whose open arrowhead represents their
  \emph{resolver}, which provides the right to choose their promise's
  target}
\label{fig:pipeline}
\end{figure}

Figure~\ref{fig:pipeline} depicts an unresolved reference as an arrow
stretching between its promise-end, the tail held by \var{r1}, and its
resolver, the open arrowhead within the pending delivery sent to
\vat{X}. Messages sent on a reference are always ``moved'' as close to
the arrowhead as possible. While the pending delivery for \code{a()}
is in transit to \vat{X}, so is the arrowhead for \var{r1}, so we send
the \code{c(r2)} message there as well. As \vat{X} unserializes these
three requests, it places the first two in its local to-do list, since
their target is known and local. The third is sent on a local promise
that will be resolved by the outcome of \code{a()}, carrying as an
argument a local promise for the outcome of \code{b()}.

If the resolution of \var{r1} is on \vat{X}, then as soon as
\code{a()} is done, \code{c(r2)} is immediately queued on \vat{X}'s
to-do list, and may well be serviced before \vat{W} learns of
\var{r1}'s resolution. If \var{r1} is on \vat{W}, then \code{c(r2)} is
streamed back towards \vat{W} just behind the message informing
\vat{W} of \var{r1}'s resolution.

Across geographic distances, latency is already the dominant
performance consideration. As hardware improves, processing will
become faster and cheaper, buffers larger, and bandwidth greater; with
limits still many orders of magnitude away. But latency will remain
limited by the speed of light. Pipes between fixed endpoints can be
made wider but not shorter.

Our promise pipelining protocol is approximately a symmetric
generalization of Bogle's ``Batched Futures'' \cite{bogle:batched},
and shares its virtues regarding network latency. (See also
\cite{liskov:promises}.)

\subsection{Datalock}

Promise chaining allows some plans, like \code{c(r2)}, to be postponed
pending the resolution of previous plans. We introduce other ways to
postpone plans below.  Using the primitives introduced so far, it is
possible to create cyclic postponement dependencies which, like
deadlock, are a form of lost-progress bug. We call this new kind of
bug \emph{datalock}. Consider:
%
\begin{alltt}
    var \dvar{flag} := null
    def \dobj{epimenides}() \{ return flag <- not() \}
    flag := epimenides <- run()
\end{alltt}
%
Let's say \var{epimenides} was written with the requirement that,
before it is called, a promise for a boolean is assigned to the
\var{flag} variable. Under this assumption, \var{epimenides} returns a
promise for the opposite boolean. The above assignment statement seems
to satisfy these requirements: If an immediate-call to
\var{epimenides} would be considered of type ``promise for boolean'',
then an eventual-send has the same type, since ``promise for promise
for $T$'' is the same as ``promise for $T$''. By eventual-sending the
invocation of \var{epimenides}, we postpone it till after the current
turn, so that \var{flag} is assigned in the current turn before
\var{epimenides} is invoked. Reasoning only locally, in terms of
conventional typing, it seems we satisfied \var{epimenides}'
requirements and invoked it correctly. But the computation of
\var{flag}'s resolution is postponed until after \var{flag} has
resolved. \oops{still unclear, and now it's awkward too}

Although we have traded one form of lost-progress bug for another, we
are still better off. Deadlock bugs are usually much more
non-deterministic than other bugs---leading to hard to reproduce
occurrences. Datalock bugs are as deterministic as normal
bugs. \oops{explain why} For example, the code above will always
produce the same datalock bug. This is the good news we understand.

We have more good news to report, although it is news we cannot yet
explain. Empirically, in many years of programming in E and E-like
languages and a body of experience spread over perhaps 60 programmers,
including two substantial distributed systems, we know of only two
accidental datalock bugs. Did others go undetected? We don't
know. What we do know is that these projects did not spend the
agonizing time chasing deadlock bugs that projects of their nature
normally do. Although we have some speculations, on the whole we are
at a loss to explain the magnitude of this effect.

\subsection{Explicit Promises}

Besides the implicit creation of promise-resolver pairs by
eventual-sending, E provides a primitive to create these pairs
explicitly. In the following code
%
\begin{alltt}
    def [\dvar{p}, \dvar{r}] := Ref.promise()
\end{alltt}
%
the right side creates and returns a new promise-resolver pair as a
two element list. The left side pattern-matches this pair, binding
\var{p} to the promise and \var{r} to its resolver. Explicit promise
creation gives us yet greater flexibility to postpone plans until
other conditions occur. The promise, \var{p}, can be handed out and
used just as any other eventual reference. All messages
eventually-sent to \var{p} are queued in \var{p}. An object with
access to \var{r} can wait until some condition occurs before
resolving \var{p} and allowing these stalled messages to proceed.

\subsection{Broken Promise Contagion}

What if \name{X}'s \meth{a()} method completes, not by
returning a result, but by throwing an exception, \ex{EX}? In the
local sequential case, this aborts the forward progress of the plan in
motion, so \code{b()} and \code{c(r2)} are never delivered, and aborts
the caller's plan as well, and so on until it reaches an exception
handling block of some sort. This has some nice fail-stop
properties. It aborts all plans whose assumptions were violated, and
whose formulation gave no indication that they were prepared for this
contingency, throwing away their temporary state. Execution resumes
only at the first enclosing contingency plan. This is control-flow
exception handling. This pattern has some difficult hazards, but these
are beyond the scope of this paper.

In the eventual case, when \code{a()}, \code{b()}, and \code{c(r2)}
were eventually-sent requests, \vat{W} doesn't have the option of
terminating the caller's plan; \vat{W} doesn't even know there's a
problem until well after the caller's turn is done. Instead, the
promised result becomes a \emph{broken reference}. A near
reference will carry both immediate-calls and eventual-sends to its
target. An eventual reference will carry eventual-sends to its
target. A broken reference will carry neither.

A broken reference has an attached exception that provides the alleged
reason why it is broken. In our scenario, \var{r1}'s promise becomes
broken by \ex{EX}. When a message is eventually-sent to a broken
reference, the message is never delivered, and the promise for the
result of the message eventually becomes broken with this same
exception. In our scenario: \code{a()} throws \ex{EX}. \vat{X} reports
this outcome to \var{r1}'s resolver. This causes an outcome report to
be sent to \vat{W}, eventually breaking \var{r1}. 
%
\oops{Suggested replacement:
When a message is eventually-sent to a broken reference, the resulting
promise becomes a broken reference with the same exception.  In our
scenario, \meth{a()} throws \ex{EX}.  \vat{X} reports this outcome to
\var{r1}'s resolver, which transmits it to \vat{W}, eventually
breaking \var{r1}.
}
%
It also immediately breaks the local promise on which \code{c(r2)} is
queued, causing the \code{c(r2)} message to be dropped, but reporting
this outcome to its resolver, breaking \var{r3} with \ex{EX} as
well. 
%
\oops{Suggested replacement:
The exception also immediately breaks VatB's local promise on which
\code{c(r2)} is queued, causing the \code{c(r2)} message to be
dropped. This outcome is reported to its resolver, which breaks
\var{r3} with \ex{EX} as well.
}
%
Having finished the \code{a()} turn, \vat{X} delivers \code{b()} to
\name{Y} and resolves \var{r2} to the outcome.

Unlike the sequential case, in the eventual case \code{b()} still gets
delivered. The aborting of plans still spreads to abort dependent
plans whose assumptions are likely violated, but this spread only
follows data dependencies, not plan sequence. E's split between
control-flow exceptions and data-flow exceptions was inspired by the
distinction between signaling and non-signaling NaNs in floating
point. Like non-signaling NaNs, broken promise contagion does not
hinder pipelining.

\section{Partial Failure}

Not all exceptional conditions are caused by program behavior.
Networks suffer outages, partitioning one part of the network from
another. Machines fail: sometimes in a transient fashion, rolling back
to a previous stable state; sometimes permanently, making the objects
they host forever inaccessible. From a machine not able to reach a
remote object, it is generally impossible to tell which failure is
occurring, or which messages were lost.

Distributed programs need to be able to react to these conditions, so
that surviving components can continue to provide valuable and
correct, even if degraded, service while other components are
inaccessible. If these components may change state while out of
contact, when they become accessible to each other again, they must
recover distributed consistency. There is no single best strategy for
maintaining consistency in the face of partitions and merges. The
strategy appropriate will depend on the semantics of the components. A
general purpose framework should provide simple mechanisms adequate to
express a great variety of strategies. Group membership and similar
systems provide one form of such a general framework, with strengths
and weaknesses in comparison with E. Here, we explain E's
framework. We provide a brief comparison with group membership-like
mechanisms in the ``Related Work'' section below.

E's support for partial failure starts by extending the semantics of
our live reference states. Figure~\ref{fig:refstates} shows the full
state transition diagram among these states.

\begin{figure}
\centerline{\epsfig{figure=refstates2.eps}}
\caption{A \emph{resolved} reference's target is known. Near
  references are resolved and local; they carry both immediate-calls
  and eventual-sends. Promises and vat-crossing references are
  eventual; they carry only eventual-sends. Broken references carry
  neither. Promises may become resolved, and vat-crossing references
  may get broken by partition \oops{mention statecharts}}
\label{fig:refstates}
\end{figure}

We've added the possibility of a vat-crossing reference---a remote
promise or a far reference---getting broken by a partition. A
partition between a pair of vats eventually breaks all references that
cross between these vats, creating eventual common knowledge of the
loss of connection. Of all the references crossing in a given
direction between two vats, a partition breaks all these references
simultaneously. Of the messages that were still in transit, the sender
can't know which were actually received and which were lost. Of
successive messages sent on the same reference, later messages will
only be delivered if all earlier messages sent on that same reference
were already delivered. This fail-stop FIFO delivery order relieves
the sender from needing to wait for earlier messages to be
acknowledged before sending later dependent messages.\footnote{
%
The message delivery order E enforces is stronger than FIFO and weaker
than Causal \cite{tribble:channels}, but FIFO is adequate for all
points we make in this paper.}

On our state-transition diagram, we see that ``near'' and ``broken''
are terminal states. Even after a partition heals, all live references
broken by that partition stay broken.

Returning to our listener example, if a partition separates \vat{A}
from \vat{S}, the \abst{statusHolder}'s reference to the spreadsheet's
listener will eventually be broken with a partition-exception. Of the
\meth{statusChanged} messages sent by the \abst{statusHolder}, this
reference will deliver them reliably in FIFO order until it
fails. Once it fails to deliver a message, it will never deliver any
further messages, and it will eventually become visibly broken.

To avoid unnecessary storage and messages, the \abst{statusHolder}
could test whether each listener reference was broken before sending
another \meth{statusChanged} message to it, but it need not, since
messages eventually-sent to broken references are harmless. They are
dropped, and promises for their result are broken by the same
exception. Instead, our \abst{statusHolder} arranges to be notified
when these references break. It does this by using another
listener-like pattern---one built into E's references---that we call
the \emph{reactor pattern}. The differences between reactors and
listeners are beyond the scope of this paper, but the terminology
difference will help us keep the levels distinct. Rather than
\emph{subscribing} a \emph{listener} to be notified, one
\emph{registers} a \emph{reactor} to be notified.

\subsection{Listening to references}

For each of the its listener references, the \abst{statusHolder} needs
to register a reactor to eventually be notified if that reference
breaks. Once notified, this reactor reacts by removing this reference
from the \abst{statusHolder}'s \var{myListener}'s list.
%
\begin{alltt}
    to \dmeth{addListener}(\dvar{newListener}) \{
        myListeners.push(newListener)
        def \dobj{reactor}(\dvar{ref}) \{
            if ((def \dvar{i} := myListeners.indexOf1(ref)) >= 0) \{
                myListeners.remove(i)
            \}
        \}
        newListener <- \_\_whenBroken(reactor)
    \}
\end{alltt}
%
The \meth{\_\_whenBroken} message is one of a handful of universally
understood messages that all objects respond to by default. (In Java,
the methods defined in \code{java.lang.Object} are similarly
universal.) Of these, the following messages are for interacting with
a reference itself, as distinct from interacting only with the object
designated by a reference. The first two are registration messages
specially understood by references. The third is a notification
message specially generated by references.
%
\begin{description}
\item[\code{\_\_whenBroken(\dvar{reactor})}] When sent on a reference,
  this message registers its argument to be notified when this
  reference breaks.
\item[\code{\_\_whenMoreResolved(\dvar{reactor})}] When sent on a
  reference, this message is normally used so that one can react when
  the reference is first resolved. We explain this in the later
  ``When-Catch'' section below.
\item[\code{\_\_reactToLostClient(\dvar{exception})}] When a
  vat-crossing reference breaks, it sends this message to its target
  object, to notify it that some of its clients may no longer be able
  to reach it.
\end{description}
%
We first explain the \meth{\_\_whenBroken} message.

Near references and local promises make no special case for these
messages---they merely deliver them to their target. Objects by
default respond to a \meth{\_\_whenBroken} message by ignoring it. So,
in our single-vat scenario, when all these references are near, the
additional code above has no effect. A broken reference responds by
eventual-sending itself as argument to the reactor, as if by the
following code:
%
\begin{alltt}
    to \dmeth{\_\_whenBroken}(\dvar{reactor}) \{ reactor <- run(self) \}
\end{alltt}
%
When a local promise becomes broken, it forwards all messages it's
buffering to the broken reference is has resolved to. 

A vat-crossing reference notifies these reactors if it becomes broken,
whether by partition or resolution. In order to be able to send these
notifications during partition, a vat-crossing reference registers the
reactor argument of a \meth{\_\_whenBroken} message at the tail-end of
the reference---within the sending vat. If the sending vat is told
that one of these references has resolved, it re-sends equivalent
\meth{\_\_whenBroken} messages to this resolution. If the sending vat
decides that a partition has occurred (perhaps because the internal
keep-alive timeout has been exceeded), it breaks all outgoing
references and notifies all registered reactors.

For all the reasons previously explained, the reactor pattern built
into E's references only eventual-sends notifications to reactors, so
they only react eventually. Until the above reactor reacts, the
\abst{statusHolder} will continue to harmlessly use the broken
reference to the spreadsheet's listener. Once again, we have separated
contingency concerns from normal operation. Plans that express no
preparation for partition, but are otherwise correct, are prevented
from doing any harm.

But what of our spreadsheet? We have ensured that it will receive
\meth{statusChanged} notifications in order, and that it will not miss
any in the middle of a sequence. But, during a partition, its display
may become arbitrarily stale. Technically, this introduces no new
correctness hazards. By the time a listener receives a
\meth{statusChanged} message, the \var{newStatus} argument may already
be stale anyway, even in the single-vat scenario. Between vats, this
issue is unavoidable because of network delays. But the spreadsheet
may wish to provide a visual indication that the displayed value may
now be more stale than usual, since it is now out of contact with the
authoritative source. To make this convenient, when a reference is
broken by partition, it eventual-sends a \meth{\_\_reactToLostClient}
message to its target, notifying it that at least one of its clients
may no longer be able to send messages to it. By default, objects
ignore \meth{\_\_reactToLostClient} messages. By overriding this
default to update the display as follows, the spreadsheet's listener
effectively acts as a reactor, registered on all references which
designate it.
%
\begin{alltt}
    to \_\_reactToLostClient(exception) \{ {\it ...update display...} \}
\end{alltt}
%
Thus, when a vat-crossing reference is severed by partition,
notifications are eventually-sent in both directions.

This explains how connectivity is safely severed by partition, and how
objects on either side can react if they wish. But objects also need
to regain connectivity following a partition. For this purpose, we
introduce \emph{sturdy references}.

\subsection{Sturdy references}

A sturdy reference in E has two forms: a ``captp://...'' URI string
and an encapsulated \code{SturdyRef} object. Both contain the same
information: the fingerprint of the public key of the vat hosting its
target object, a list of TCP/IP location hints to seed the search for
a vat that can authenticate against this fingerprint, and a so-called
\emph{swiss-number}, a large unguessable random number which the
hosting vat associates with the target \cite{tyler:yurl}. Like the
popular myth of how Swiss bank account numbers work, one demonstrates
knowledge of this secret to gain access to the object it designates.
Like an object reference, if you don't know an unguessable secret, you
can only come to know it if someone who knows it and can talk to you
chooses to tell it to you. A sturdy reference is a form of off-line
``password'' capability---it contains the cryptographic information
needed both to authenticate the target and to authorize access to the
target \cite{jed:dccs}.

Both forms of sturdy reference are pass-by-copy, and can be passed
between vats even when the target vat is inaccessible. Sturdy
references do not directly convey messages to their target. To
establish or reestablish access to the target, one makes a new live
reference from a sturdy reference. Doing so initiates a new attempt to
connect to the target vat, and immediately returns a promise for the
resulting inter-vat reference. If the connection attempt fails, this
promise is eventually broken.

Typically, most vat-crossing references are represented only as live
references. When these break, applications on either end should not
try to recover the detailed state of all the plans in progress between
these vats. Instead, they should typically go back to the small number
of sturdy references from which this complex structure was originally
spawned, and use these to spawn a new fresh structure. As part of this
respawning process, the two sides may need to reconcile---to
reestablish distributed consistency.

In our listener example, the \abst{statusHolder} should not hold
sturdy references to listeners, and should not try to reconnect to
them. This would put the burden on the wrong party. A better design
would have a listener hold a sturdy reference to the
\abst{statusHolder}. The listener's \meth{\_\_reactToLostClient}
method would be enhanced to attempt to reconnect to the
\abst{statusHolder} and to resubscribe the listener on the promise for
the reconnected \abst{statusHolder}. 
%
\oops{Should we place the following text earlier, maybe much earlier?}
So that subscribed and re-subscribed listeners start with a valid
state, we should change \abst{statusHolder}'s \meth{addListener}
method to send an initial \meth{statusChanged} message, notifiying
newly subscribed listeners of the current state.

But perhaps the spreadsheet application originally encountered this
\abst{statusHolder} by navigating from an earlier object representing
a collection of accounts, creating and subscribing a spreadsheet cell
for each. While the vats were out of contact, not only may this
\abst{statusHolder} have changed, the collection may have changed so
that this \abst{statusHolder} is no longer relevant. In this case, a
better design would be for the spreadsheet to maintain a sturdy
reference only to the collection as a whole. When reconciling, it
should navigate afresh, in order to find the \abst{statusHolder}s it
now needs to subscribe to.

By separating live vs sturdy references, we encourage programming
patterns that separate reconciliation concerns from normal operations.

\subsection{Persistence}

For an object that is designated only by live references, the hosting
vat can tell when it is no longer reachable, and can garbage collect
it.\footnote{
%
E's distributed garbage collection protocol does not currently collect
unreachable inter-vat cycles of live references. See \cite{bejar:gc}
for a gc algorithm able to collect such cycles among mutually
suspicious machines.}
%
Once one makes a sturdy reference to a given object, its hosting vat
can no longer determine when it is unreachable. Instead, this vat must
retain the association between this object and its swiss number until
its obligation to honor this sturdy reference expires.

The operations for making a sturdy reference provide three options for
ending this obligation: It can expire at a chosen future date, giving
the association a \emph{time-to-live}. It can expire when explicitly
cancelled, making the association \emph{revocable}. And it can expire
when the hosting vat crashes, making the association
\emph{transient}. Here, we examine only this last option. An
association which is not transient is \emph{durable}.

A vat can be either ephemeral or persistent. An ephemeral vat exists
only until it terminates or crashes; so for these, the last option
above is irrelevant. A persistent vat periodically \emph{checkpoints},
saving its persistent state to non-volatile storage. A vat checkpoints
only between turns when its stack is empty. A crash terminates a
vat-incarnation. Reviving the vat from checkpoint creates a new
incarnation of the same vat. A persistent vat lives through a sequence
of incarnations.

The persistent state of a vat is determined by traversal from
persistent roots. This state includes the vat's public/private key
pair, so later incarnations can authenticate. It also includes all
unexpired durable swiss-number associations, and state reached by
traversal from there. As this traversal proceeds, when it reaches a
sturdy reference, the sturdy reference itself is saved, but it is not
traversed to its target. When the traversal reaches a live inter-vat
reference, a broken reference is saved instead, and the reference is
again not traversed. Should this vat be revived from this checkpoint,
old live inter-vat references will be revived as broken references. A
crash partitions a vat from all others. Following a revival, only
sturdy references in either direction enable it to become reconnected.

\section{The When-Catch Expression}

To be notified when a reference resolves, one registers a reactor
using the \meth{\_\_whenMoreResolved} message. But programmers rarely
use this message directly. Instead they use the higher-level
``when-catch'' syntactic shorthand, whose semantics we explain here by
example.

Let's say you'd like to buy something, but only after you receive
satisfying answers to a few questions. The servers which can answer
these questions are remote, so you eventual-send queries, and
accumulate the resulting promises-for-boolean-answers into a list. You
can use the following \var{asyncAnd} function to compute the
eventual-conjunction of these promises.
%
\begin{alltt}
    def \dobj{asyncAnd}(\dvar{answers}) \{
        var \dvar{countDown} := answers.size()
        if (countDown == 0) \{ return true \}
        def [\dvar{result}, \dvar{resolver}] := Ref.promise()
        for \dvar{answer} in answers \{
            when (answer) -> \{
                if (answer) \{
                    if ((countDown -= 1) == 0) \{
                        resolver.resolve(true) 
                    \}
                \} else \{
                    resolver.resolve(false)
                \}
            \} catch \dvar{exception} \{
                resolver.smash(exception)
            \}
        \}
        return result
    \}
\end{alltt}
%
Let's see how this code works.

If the list is empty, the conjunction is true, and we're
done. Otherwise, \var{countDown} remembers how may true answers we
still need to hear before we can conclude that the conjunction is
true. We iterate through the answers list, using the ``when-catch''
expression to register a reactor on each reference in the list. The
behavior of the reactor is expressed in two parts: the code between
``\code{->~\{}'' and ``\code{\}~catch}'' handles the normal case, and
the catch-clause handles the exceptional case. Once \var{answer}
resolves, if it's near or far, the normal-case code is run. If it's
broken, the catch-clause is run.

Here, if the normal case runs, we expect \var{answer} to be a
boolean. Booleans are passed-by-copy between vats, so a resolved
reference to a boolean is always a near reference to a local copy of
the boolean. By using a ``when-catch'', we postpone the \code{if}
until we've gathered enough information to know which way it should
branch.

Once \var{asyncAnd} registers all these reactors, it immediately
returns \var{result}, a promise for the conjunction of these
answers. If they all resolve to true, \var{asyncAnd} \emph{reveals}
that the result is true, i.e., it eventually resolves the
already-returned promise to true. If any resolve to false,
\var{asyncAnd} reveals false without waiting for further answers. If
any resolve to broken, \var{asyncAnd} reveals a reference broken by
the same exception. Asking a resolver to resolve an already-resolved
promise has no effect. If one of the answers is false and another is
broken, the above \var{asyncAnd} code may reveal either false or
broken, depending on which reactor happens to be notified first.

Now that we understand how ``when-catch'' works, we see how you can
use it together with \var{asyncAnd} to postpone your purchase until
your questions are satisfied.
%
\begin{alltt}
    def \dvar{allOk} := asyncAnd([inventory <- isAvailable(partNo),
                           creditBureau <- verifyCredit(name),
                           shipper <- canDeliver(...)])
    when (allOk) -> \{
        if (allOk) \{
            def \dvar{receipt} := seller <- buy(partNo, payment)
            when (receipt) -> \{
\end{alltt}
%
Promise chaining postpones plans efficiently by data-flow. The
``when-catch'' postpones plans until data-flow can be turned back into
control-flow.

\section{From Objects to Actors and Back Again}

Here we present a brief history of the concurrency-control ideas
explained above. In this section, the term ``we'' indicates that at
least one of this paper's authors participated in a project involving
other people. All implied credit should be understood to be shared
with these others.

\subsection{From Objects to Actors}

The nature of computation provided within a single von Neumann machine
is quite different than the nature of computation provided by networks
of such machines. Distributed programs must deal with both. To reduce
cases, it would seem attractive to create an abstraction layer that
can make these seem more similar. Distributed Shared Memory systems
\cite{dsm-survey} try to make the network seem more like a von Neumann
machine. Object-oriented programming started by trying to make a
single computer seem more like a network.
%
\begin{quotation}
\ldots Smalltalk is a recursion on the notion of computer
itself. Instead of dividing ``computer stuff'' into things each less
strong than the whole---like data structures, procedures, and
functions which are the usual paraphernalia of programming
languages---each Smalltalk object is a recursion on the entire
possibilities of the computer. Thus its semantics are a bit like
having thousands and thousands of computers all hooked together by a
very fast network.
\begin{flushright}
---Alan Kay \cite{kay:smallhistory}
\end{flushright}
\end{quotation}
%
Smalltalk imported only the aspects of networks that made it easier to
program a single machine---its purpose was not to achieve network
transparency. Problems that could be avoided within a single
machine---like inherent asynchrony, large latencies, and partial
failures \cite{waldo:note}---were avoided. The sequential subset of E
has much in common with the early Smalltalk: Smalltalk's object
references are like E's near references, and Smalltalk's message
passing is like E's immediate-call operator.

\related{Actors.} Inspired by the early Smalltalk, Hewitt created the
Actors paradigm \cite{hewitt:actors}, whose goals include full network
transparency within all the constraints imposed by decentralization
and mutual suspicion \cite{hewitt:challenge}. Although the stated
goals require the handling of partial failure, the actual Actors model
assumes this issue away, and instead guarantees that all sent messages
are eventually delivered. The asynchronous-only subset of E is an
Actors language: Actors' references are like E's eventual references,
and Actors' message passing is much like E's eventual-send
operator. Actors provided both data-flow postponement of plans by
futures (like E's promises without pipelining or contagion) and
control-flow postponement by continuations (similar in effect to E's
when-catch).

The price of this uniformity is that all programs had to work
in the face of network problems. There was only one case to solve, but
it was the hard case.

\related{Vulcan.} The Vulcan project \cite{kahn:vulcan}
merged aspects of Actors and concurrent logic/constraint programming
\cite{tr003,Saraswat93,janus}. The pleasant properties of concurrent
logic variables (much like futures or promises) taught us to emphasize
data-flow postponement and de-emphasize control-flow
postponement. 

\oops{This MUST credit Shapiro and probably Takeuchi}

Vulcan was built on a concurrent logic base, and inherited from this
base the so-called ``merge problem'' \cite{Shapiro:merge} absent from
pure Actors languages: Clients can only share access to a stateful
object by explicit pre-arrangement, so the equivalent of object
references were not usefully first-class. To address this problem, we
created the ``Channels'' abstraction, which also provides useful
ordering properties \cite{tribble:channels}.

\related{Promise pipelining in Udanax Gold.} This was a
pre-web hypertext system with a rich interaction protocol between
clients and servers. To deal with network latencies, in the 1989
timeframe, we independently reinvented an asymmetric form of promise
pipelining as part of our protocol design \cite{gold:promises}. The
core idea was invented earlier by Liskov and Shrira
\cite{liskov:promises}.

\oops{udanax promises were explicitly a sequential adaptation of joule
channels, and predated the liskov work, I believe. Dean, call me.}

\related{Joule.} The \sys{Joule} language \cite{tribble:joule}
merges insights developed during the \sys{Vulcan} project with
remaining virtues of Actors, and the order preserving properties of
the ``Channels'' abstraction invented during the Vulcan
project. Joule's Channels are similar to E's promises generalized to
provide multicasting. \oops{Dean, please call me}

\subsection{And back again}

\related{Original-E.} The language now known as
\sys{Original-E} was the result of adding the concepts from Joule to
the sequential, capability-secure subset of Java, and extending the
Joule-like portion of the language cryptographically over the
network. Electric Communities created \sys{Original-E}, and used it to
build \sys{Habitats}---a graphical, decentralized, secure, social
virtual reality system. Our ambitions included secure
user-extensibility, but the company failed before we could take this
step.

\sys{Original-E} was the first to successfully mix sequential
immediate-call programming with asynchronous eventual-send
programming. This is where we first came to appreciate the importance
of the vat as the container of sequentiality, and as the unit of
separate failure, persistence, and migration. \oops{Dean, How much of
  this should be attributed instead to the Joule ``tank''?}

\related{From Original-E to E.} In \sys{Original-E}, the
co-existence of sequential and asynchronous programming was still
rough. E brought the invention of the distinct reference states and
the transitions among them explained in this paper. With these rules,
E bridges the gap between the network-as-metaphor view of the early
Smalltalk and the network-transparency ambitions of Actors. Notice
that all the examples presented in this paper happen to work when all
the objects involved are local. The local case is strictly easier than
the network case, so the guarantees provided by near references are a
strict superset of the guarantees provided by other reference
states. When programming for known-local objects, a programmer can do
it the easy way. Otherwise, the programmer must do it the hard
way. There are still two cases, but there isn't the cost of two cases.

If you don't know that the relevant objects are local, your code must
be prepared to handle the inescapable hard problems of networks. But
once you've done so, the same code will painlessly also handle the
local case without requiring any further case analysis.

\section{Related Work}

\related{Promises and Batched Futures at MIT.} The promise
pipelining technique was first invented by Liskov and Shrira
\cite{liskov:promises}. These ideas were then significantly improved
by Bogle \cite{bogle:batched}. Like the \sys{Udanax Gold} system
mentioned above, these are asymmetric client-server systems. In other
ways, the techniques used in Bogle's protocol resembles quite closely
some of the techniques used in E's protocol.

\related{Group Membership.} There is an extensive body of work
on group membership systems \cite{birman:vsync,amir:thesis} and
(broadly speaking) similar systems such as Paxos
\cite{lamport:paxos}. These systems provide a different form of
general purpose framework for dealing with partial failure, with both
strengths and weaknesses in comparison to E. These frameworks provide
closer approximations of common knowledge than does E, but at the
price of weaker support for mutual suspicion and scalability. These
frameworks better support the tightly-coupled composition of separate
plan-strands into a virtual single overall plan. E's mechanisms better
support the loosely coupled composition of networks of independent but
cooperative plans.

For example, when the distributed components in question jointly form
a single logical application, which provides a single logical service
to all their collective clients, and when multiple separated
components may each change state while out of contact with the others,
we have a \emph{partition-aware application}
\cite{partition-aware,bancomat}, providing some form of fault-tolerant
replication among its components. To the clients of a partition-aware
application, the application as a whole attempts to approximate, as
close as it can, a single stateful object which is highly available
under partition. Some group membership-like mechanisms shine at
supporting such application under mutually reliant and even Byzantine
conditions \cite{castro:bft}.

E itself provides nothing comparable. The patterns of fault-tolerant
replication we've built to date are all forms of primary-copy
replication, where there's a single stationary authoritative host. E
supports these patterns quite well, and they compose well with simple
E objects that are unaware they are interacting with a replica. An
area of future research is to see how well partition-aware
applications can be programmed in E, and how well they can compose
with others.

\related{Croquet and TeaTime.} The \sys{Croquet} project has
many of the same goals as the \sys{Habitats} project refered to
above---to create a graphical, decentralized, secure, user-extensible,
social virtual reality system spread across mutually suspicious
machines. Regarding E, the salient differences are that \sys{Croquet}
is built on \sys{Smalltalk} extended onto the network by
\sys{TeaTime}, which is based on \sys{Namos} \cite{reed:namos} and
\sys{Paxos} \cite{lamport:paxos}, in order to replicate state among
multiple authoritative hosts. Unlike \sys{Habitats}, \sys{Croquet} is
user-extensible, but is not yet secure. It will be interesting to see
how they alter \sys{Paxos} to work between mutually suspicious
machines.

\subsection{Work influenced by E's concurrency control}

\related{The Web-Calculus} The \sys{Web-Calculus} \cite{tyler:webcalc}
brings to web URLs the following simultaneous properties:
%
\begin{itemize}
\item The cryptographic capability properties of E's sturdy
  references---both authenticating the target and authorizing access
  to it.
\item Promise pipeling of eventually-POSTed requests with results.
\item The properties recommended by the REST model of web programming
  \cite{fielding:rest}. REST attributes the success of the web largely
  to certain loose-coupling properties of ``http://...''  URLs, which
  are well beyond the scope of this paper. See
  \cite{fielding:rest,tyler:webcalc} for more.
\end{itemize}
%
As a language neutral protocol compatible and composable with existing
web standards, the \sys{Web-Calculus} is much better positioned than E
to achieve widespread adoption. We expect to build a bridge between
E's references and \sys{Web-Calculus} URLs.

\related{Oz-E.} Like \sys{Vulcan}, the \sys{Oz} language
\cite{VanRoyHaridi} descends from both \sys{Actors} and concurrent
logic/constraint programming. Unlike these parents, \sys{Oz} supports
shared-state concurrency, though \sys{Oz} programming practice
discourages its use. \sys{Oz-E} \cite{oze} is a capability-based
successor to \sys{Oz} designed to support both local and distributed
mutual suspicion. For the reasons explained in the ``Defensive
Correctness'' section above, \sys{Oz-E} suppresses \sys{Oz}'s
shared-state concurrency.

\related{Twisted Python.} This is a library and a set of
conventions for distributed programming in Python, based on E's model
of communicating event loops, promise pipelining, and cryptographic
capability security \cite{twisted}.

\section{Discussion and Conclusions}

\oops{De-emphasize graph and access control. Status? Lessons learned?
Remaining problems? Strangers? Plan coordination?}

The dynamic reference graph is the fabric of object computation. In
this paper, we have explained how E extends the concept of the
object-reference graph, in order to provide the distributed
access control and concurrency control needed for practical, secure,
global computing.

By restricting causality to flow only along the graph, E turns the
reference graph into an access graph able to support fine-grained
\emph{least authority}. By restricting the ordering of these causal
influences, E provides deadlock-free concurrency control, able to
maintain consistency in concurrent stateful systems.  E uses safe
language techniques to enforce these restrictions within a
process. E's cryptographic protocol enforces these restrictions
between mutually suspicious machines. Distributed programs must also
face large latencies and partial failure. By changing only a few
concepts of conventional sequential object programming, E enables
programmers to handle all these issues simultaneously.

\section{Acknowledgements}
For various helpful suggestions, we thank
Darius Bacon,
Dan Bornstein,
Bill Frantz,
Ian Grigg,
Piotr Kaminski,
Alan Karp,
Matej Kosik,
Jon Leonard,
Kevin Reid,
Michael Sperber,
Fred Spiessens,
Terry Stanley,
Marc Stiegler,
Bill Tulloh,
Steve Witham,
the e-lang and cap-talk communities,
and especially
David Hopwood and
Ka-Ping Yee.
Further thanks to Ka-Ping Yee for
figures~\ref{fig:stackvat}--\ref{fig:refstates}
and to Terry Stanley for suggesting the listener pattern
and purchase-order examples.

\bibliography{common}
%\bibliographystyle{splncs}
\bibliographystyle{alpha}
\end{document}
